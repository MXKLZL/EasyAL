# References

- [D. Lewis and W. Gale. A sequential algorithm for training text classifiers. in proceedings of
  the acm sigir conference on research and development in information retrieval, pages 3â€“12.
  acm/springer, 1994.](https://arxiv.org/abs/cmp-lg/9407020)

- [Tobias Scheffer, Christian Decomain, and Stefan Wrobel. Active hidden markov models for
  information extraction, 2001.](https://link.springer.com/chapter/10.1007/3-540-44816-0_31)

- [Donggeun Yoo and In So Kweon. Learning loss for active learning, 2019.](https://arxiv.org/abs/1905.03677)

- [Ozan Sener and Silvio Savarese. Active learning for convolutional neural networks: A core-set
  approach, 2018.](https://arxiv.org/abs/1708.00489)

- [Seong Tae Kim, Farrukh Mushtaq, and Nassir Navab. Confident coreset for active learning in
  medical image analysis, 04 2020.](https://arxiv.org/abs/2004.02200)

- [Qizhe Xie, Minh-Thang Luong, Eduard Hovy, and Quoc V. Le. Self-training with noisy student
  improves imagenet classification, 2020.](https://arxiv.org/abs/1911.04252)

- [Samuli Laine and Timo Aila. Temporal ensembling for semi-supervised learning, 2017.](https://arxiv.org/abs/1610.02242)

- [Antti Tarvainen and Harri Valpola. Mean teachers are better role models: Weight-averaged
  consistency targets improve semi-supervised deep learning results, 2018.](https://arxiv.org/abs/1703.01780)



