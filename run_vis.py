# -*- coding: utf-8 -*-
"""Run.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15Cg7uoa70mKgx1pcmj8XGHAoRjrYhhCo
"""

#!unzip images.zip

#!rm -rf /content/images

import os
import numpy as np
import torch
import torch.nn as nn
import torchvision.transforms as transforms
from torchvision.transforms import Compose, ToTensor, Normalize, Resize
from sklearn.model_selection import train_test_split
from torchvision import datasets, models
import matplotlib.pyplot as plt
from GroceriesDataset import GroceriesDataset
from BaseModel import *
from query_strategy import *
from Evaluation import *
import torchvision
from collections import defaultdict
from utils import *
import os
import logging
import warnings
import pickle

try:
    os.makedirs('visualization')
except OSError as e:
    pass

class_name_map = {'BEANS': 22,
 'CAKE': 6,
 'CANDY': 2,
 'CEREAL': 20,
 'CHIPS': 4,
 'CHOCOLATE': 0,
 'COFFEE': 3,
 'CORN': 14,
 'FISH': 12,
 'FLOUR': 5,
 'HONEY': 18,
 'JAM': 21,
 'JUICE': 24,
 'MILK': 16,
 'NUTS': 7,
 'OIL': 13,
 'PASTA': 8,
 'RICE': 23,
 'SODA': 15,
 'SPICES': 9,
 'SUGAR': 10,
 'TEA': 19,
 'TOMATO_SAUCE': 17,
 'VINEGAR': 11,
 'WATER': 1}

#!nvidia-smi

NUM_INITIAL_LAB = 200
TEST_SET_RATIO = 0.2
NUM_ROUND = 15
NUM_LABEL_PER_ROUND = 100
BATCH_SIZE = 32
FIT_EPOCH = 26
#strategy = 'entropy'


configs = {'transforms': [transforms.Compose([
                                            transforms.Resize(224),
                                            transforms.RandomAffine(30, scale = (0.8,1.5)),
                                            transforms.ToTensor(),
                                            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]),
                                transforms.Compose([
                                            transforms.Resize(224),
                                            transforms.ToTensor(),
                                            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])],
          'batch_size': BATCH_SIZE,
          'epoch': FIT_EPOCH,
          'num_ft_layers': 3,
          'loss_function': nn.CrossEntropyLoss,
          'num_class': 25,
          'weighted_loss': True,
          'epoch_loss':6,
           'margin':1.0,
           'lambda':1
           }

train_path = '/content/gdrive/My Drive/SCHOOL/Capstone/content/train_split_all.txt'
test_path =  '/content/gdrive/My Drive/SCHOOL/Capstone/content/test_split_all.txt'
image_dir = '/content/gdrive/My Drive/SCHOOL/Capstone/content/images'
train_ds = GroceriesDataset(train_path,image_dir,class_name_map,configs['transforms'])

test_ds = GroceriesDataset(test_path,image_dir,class_name_map,configs['transforms'])

def get_initial_label(num):
  tmp = np.arange(len(train_ds))
  np.random.shuffle(tmp)
  return tmp[:num]

testloader = torch.utils.data.DataLoader(test_ds, batch_size=32)
test_target = test_ds.target_list
test_length = len(test_target)
test_ds.set_mode(1)



print('Initial Status')
print('Number of labeled images: {}'.format(NUM_INITIAL_LAB))
print('Number of unlabeled images: {}'.format(len(train_ds) - NUM_INITIAL_LAB))
print('Number of testing images: {}'.format(len(test_ds)))

print('')
print('Begin Train')

strategies = ['random', 'uncertain', 'entropy','margin', 'k_means', 'k_center_greedy']
allacc = []
allssim = []
allcost = []
allvar = []
alltime = []
allembed = []
label_idx_original = get_initial_label(NUM_INITIAL_LAB)


#model for embedding distance
diversity_model = models.resnet152(pretrained=True)
strategy_queries = {}
models = {}
# file = open("Fruits.obj",'rb')
# object_file = pickle.load(file)
# file.close()

print("precompute embeddings")
with open(f"/content/gdrive/My Drive/SCHOOL/Capstone/model_random.pkl", 'rb') as handle:
    Model = pickle.load(handle)
full_idx = np.arange(len(train_ds))
dataset_query = torch.utils.data.Subset(train_ds, full_idx)
data_loader_query = torch.utils.data.DataLoader(dataset_query, batch_size = 32)
embeddings = Model.get_embedding(data_loader_query)
tsne_embeddings = TSNE(n_components=2).fit_transform(embeddings.numpy())
print("done")


for strategy in strategies:
    print(strategy)
    # load model
    try:
        with open(f"/content/gdrive/My Drive/SCHOOL/Capstone/model_{strategy}.pkl", 'rb') as handle:
            Model = pickle.load(handle)
            models[strategy] = Model
    except:
        pass
    # load query_each_round
    with open(f'/content/gdrive/My Drive/SCHOOL/Capstone/result_{strategy}.pkl', 'rb') as handle:
        blob = pickle.load(handle)
        query_each_round = blob[-1]
        # print(query_each_round)
    strategy_queries[strategy] = query_each_round
#   logger = logging.getLogger()
#   old_level = logger.level
#   logger.setLevel(100)
#   print("drawing for eye balls")
#   vis(query_each_round, train_ds, class_name_map, strategy, random_sample=10)
#   logger.setLevel(old_level)

    # visualize a single strategy's sample embedding at each iteration
    print("drawing signle strategies sample emebdding at each iterations")
    tsne_vis_each_strategy(train_ds, Model, query_each_round, strategy, tsne_precompute=tsne_embeddings)
#   tsne_vis_each_strategy(train_ds, Model, query_each_round, strategy, opacity=True, tsne_precompute=tsne_embeddings)  

# every strategy and iteration on one graph
print("drawing every strategy and iteration on one graph")
# tsne_vis(train_ds, Model, strategy_queries, f"{strategy}", tsne_precompute=tsne_embeddings)
# tsne_vis(train_ds, Model, strategy_queries, f"{strategy}_op", opacity=True, tsne_precompute=tsne_embeddings)
tsne_vis_all_seperated(train_ds, Model, strategy_queries, "all", iterationLegend=False, models=None, tsne_precompute=None, by=3)
# tsne_vis_all_seperated(train_ds, Model, strategy_queries, "all", iterationLegend=False, opacity=True, models=None, tsne_precompute=None, by=4)

# visualize every strategies's sample embedding for each iteration
print("drawing every strategies's sample embedding for each iteration")
tsne_vis_each_iter(train_ds, Model, strategy_queries, tsne_precompute=tsne_embeddings)
# tsne_vis_each_iter(train_ds, Model, strategy_queries, opacity=True, models=models, tsne_precompute=tsne_embeddings)