# -*- coding: utf-8 -*-
"""query_strategy.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_G_vtAh9NwFoSrDjE_ZsY_2xTij10rxy
"""
import numpy as np
import torch
import time
from sklearn.cluster import KMeans

def query(strategy, model_class, label_per_round):
  start = time.time()

  if strategy == 'random':
    unlabel_index = model_class.get_unlabeled_index()
    np.random.shuffle(unlabel_index)

    end = time.time()
    duration = end - start
    return duration, unlabel_index[:label_per_round]

  if strategy == 'uncertain':
    unlabel_index = model_class.get_unlabeled_index()
    p, _ = torch.max(model_class.predict_unlabeled(), 1)
    selected_index = p.numpy().argsort()[:label_per_round]

    end = time.time()
    duration = end - start
    return duration, unlabel_index[selected_index]

  if strategy == 'margin':
    unlabel_index = model_class.get_unlabeled_index()
    p = model_class.predict_unlabeled()
    p = -np.sort(-p, axis=1)
    # sort every row by descending
    diff = p[:, 0] - p[:, 1]
    # get difference between first class and second class
    selected_index = np.argsort(diff)[:label_per_round]

    end = time.time()
    duration = end - start
    return duration, unlabel_index[selected_index]

  if strategy == 'entropy':
    unlabel_index = model_class.get_unlabeled_index()
    p = model_class.predict_unlabeled()
    entropy = (-p * torch.log(p)).sum(1)
    # calculate entropy for each image
    selected_index = np.argsort(entropy.numpy())[::-1][:label_per_round]

    end = time.time()
    duration = end - start
    return duration, unlabel_index[selected_index]

  if strategy == 'k_means':
    unlabel_index = model_class.get_unlabeled_index()
    embedding = np.array(model_class.get_embedding_unlabeled())
    cluster_ = KMeans(n_clusters=label_per_round)
    cluster_.fit(embedding)
    cluster_index = cluster_.predict(embedding)
    centers = cluster_.cluster_centers_[cluster_index]
    dis = np.sum(np.array(pow((embedding - centers), 2)), axis=1)

    centerlabels = []
    for i in range(label_per_round):
      clusterlabel = np.where(cluster_index == i)[0]
      centerlabels.append(clusterlabel[dis[clusterlabel].argsort()[0]])

    end = time.time()
    duration = end - start
    return duration, unlabel_index[centerlabels]

  if strategy == 'k_center_greedy':
    unlabel_index = model_class.get_unlabeled_index()
    unlabel_embedding = np.array(model_class.get_embedding_unlabeled())
    label_index = model_class.labeled_index
    label_embedding = np.array(model_class.get_embedding(model_class.data_loader_labeled))

    # for each unlabeled dataset i, compute its distance with all labeled j, 
    # and find the smallest distance
    min_dists = []
    for i in range(len(unlabel_embedding)):
      l2_dists = np.linalg.norm(unlabel_embedding[i] - label_embedding, axis=1)
      min_dists.append(l2_dists.min())

    selected_index = np.argsort(min_dists)[::-1][:label_per_round]
    # find the unlabeled dataset i with largest minimal distance 
    end = time.time()
    duration = end - start
    return duration, unlabel_index[selected_index]
